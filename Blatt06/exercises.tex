\section*{Aufgabe 1: \emph{kNN: Implementierung}}
\begin{itemize}
\item[a)] Wenn sich Attribute sehr stark in ihren Größenordnungen unterscheiden ist der euklidische Abstand zwischen ihnen nicht sehr Aussagekräftig. Um dieses Problem zu beheben kann eine normierung der Attribute durchgeführt werden.

\item[b)] Der kNN wird als lazy-learner bezeichnet, da kein wirkliches Modell gebildet wird, sondern das Modell für jedes Testset neu berechnet wird. Dadurch sind die Laufzeiten für die "Anwendung" des Modells groß. Die "Lernphase" ist dabei allerdings kurz bzw in der Anwendungszeit enthalten. Ein Random Forest Algorithmus trainiert zunächst mit langer Laufzeit ein Modell, das dann in kurzer Zeit auf die Testdaten angewendet werden kann.

\item[c)] -> aufgabe1.py
\item[d),e),f)]
\begin{align*}
	k &=10 \\
	\mathrm{Reinheit: } &= 0.971604447974583 \\
	\mathrm{Effizienz: } &=0.9786 \\
	\mathrm{Accuracy : } 0.975 \\
	\mathrm{Signifikanz: } &= 50.36 \\
	\mathrm{Laufzeit : } &= 114.47622203826904 \\
	k &=20 \\
	\mathrm{Reinheit: } &=  0.9601822503961965 \\
	\mathrm{Effizienz: } &= 0.9694\\ 
	\mathrm{Accuracy: } &= 0.9646\\
	\mathrm{Signifikanz: } &=  50.48 \\
	\mathrm{Laufzeit: } &=136.59338474273682 \\
	\mathrm{log10(AnzahlHits)}&\\
	k &=10 \\
	\mathrm{Reinheit: } &=1.0\\
	\mathrm{Effizienz: } &=1.0\\
	\mathrm{Accuracy: } &=1.0\\
	\mathrm{Signifikanz: } &=50.0 \\
	\mathrm{Laufzeit :} &= 185.95175766944885 \\
	k &=20 \\
	\mathrm{Reinheit: }&= 1.0 \\
	\mathrm{Effizienz: }&= 0.9998 \\
	\mathrm{Accuracy: }&=  0.9999 \\
	\mathrm{Signifikanz: }&=  49.99 \\
	\mathrm{Laufzeit: }&= 186.45055532455444 \\
\end{align*}


\end{itemize}
\section*{Aufgabe 2: \emph{kMeans per Hand}}

\section*{Aufgabe 3: \emph{Feature Selection mit dem MRMR--Algorthmus}}
