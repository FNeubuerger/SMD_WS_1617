{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple mainly linear regressions with sklearn for the Housing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import autosklearn.regression\n",
    "import sklearn.preprocessing as skp\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the training and test data into Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv',index_col=0)\n",
    "test = pd.read_csv('test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data so sklearn can read it, fill NaNs with means of the columns, and transform the categorical attributes with dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.log(train.pop('SalePrice'))#log transform the target\n",
    "all_df = pd.concat((train,test),axis=0) #concat the training and test data for faster preprocessing\n",
    "\n",
    "all_df['MSSubClass']=all_df['MSSubClass'].astype(str) #Datatype fixes\n",
    "\n",
    "all_dummy = pd.get_dummies(all_df)\n",
    "\n",
    "mean_cols=all_dummy.mean() #calculate means of the categorical columns\n",
    "\n",
    "all_dummy = all_dummy.fillna(mean_cols)\n",
    "#Split the datasets back into training and test set\n",
    "dummy_train = all_dummy.loc[train.index]\n",
    "dummy_test = all_dummy.loc[test.index]\n",
    "#prepare data for sklearn\n",
    "X_train = dummy_train.values\n",
    "X_test = dummy_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The now (simple) preprocessed data can be fed into sklearn methods. Further Preprocessing and simple feature generation should be done before this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the used models from sklearn and some handy utility. Simple linear models will be used in this notebook. In addition a Random Forest Regressor will be also used. The optimal parameters will be calculated using the CV method provided in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LassoCV,Lasso,ElasticNet, ElasticNetCV,RidgeCV,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor , AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elnet_cv = ElasticNetCV()\n",
    "ridge_cv = RidgeCV(alphas=np.arange(1,100,10))\n",
    "rf = RandomForestRegressor(n_estimators = 500)\n",
    "ada = AdaBoostRegressor(n_estimators = 500)\n",
    "gbr = GradientBoostingRegressor(n_estimators = 500)\n",
    "lasso_cv = LassoCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the models to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.05048139342\n",
      "11\n",
      "1.02524069671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elnet_cv.fit(X_train,y_train)\n",
    "print(elnet_cv.alpha_)\n",
    "ridge_cv.fit(X_train,y_train)\n",
    "print(ridge_cv.alpha_)\n",
    "lasso_cv.fit(X_train,y_train)\n",
    "print(lasso_cv.alpha_)\n",
    "rf.fit(X_train,y_train)\n",
    "ada.fit(X_train,y_train)\n",
    "gbr.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0252406967113168, copy_X=True, fit_intercept=True,\n",
       "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elnet = ElasticNet(elnet_cv.alpha_)\n",
    "ridge = Ridge(ridge_cv.alpha_)\n",
    "lasso = Lasso(lasso_cv.alpha_)\n",
    "elnet.fit(X_train,y_train)\n",
    "ridge.fit(X_train,y_train)\n",
    "lasso.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_1 = np.exp(elnet.predict(X_test))\n",
    "y_2 = np.exp(ridge.predict(X_test))\n",
    "y_3 = np.exp(rf.predict(X_test))\n",
    "y_4 = np.exp(ada.predict(X_test))\n",
    "y_5 = np.exp(gbr.predict(X_test))\n",
    "y_6 = np.exp(lasso.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate the expected testscore via a 5-fold-cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19814470818553748, 0.13898984113918872, 0.14205099881735989, 0.17157781509512335, 0.12340387488925017, 0.19812150361970698]\n",
      "0.162048123624\n"
     ]
    }
   ],
   "source": [
    "score1 = np.mean(np.sqrt(-cross_val_score(elnet,X_train,y_train,cv=5,scoring='neg_mean_squared_error')))\n",
    "score2 = np.mean(np.sqrt(-cross_val_score(ridge,X_train,y_train,cv=5,scoring='neg_mean_squared_error')))\n",
    "score3 = np.mean(np.sqrt(-cross_val_score(rf,X_train,y_train,cv=5,scoring='neg_mean_squared_error')))\n",
    "score4 = np.mean(np.sqrt(-cross_val_score(ada,X_train,y_train,cv=5,scoring='neg_mean_squared_error')))\n",
    "score5 = np.mean(np.sqrt(-cross_val_score(gbr,X_train,y_train,cv=5,scoring='neg_mean_squared_error')))\n",
    "score6 = np.mean(np.sqrt(-cross_val_score(lasso,X_train,y_train,cv=5,scoring='neg_mean_squared_error')))\n",
    "scores = [score1,score2,score3,score4,score5,score6]\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since ridge, random forest and gradient boost seems to have the best performance on test data the average of those regressors is taken for the final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_final = (y_2+y_3+y_5)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(data={'Id':test.index,'SalePrice':y_final})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_final_ridge_rf_gbr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
